{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>Body</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>LastActivityDate</th>\n",
       "      <th>Title</th>\n",
       "      <th>...</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>ContentLicense</th>\n",
       "      <th>LastEditorDisplayName</th>\n",
       "      <th>LastEditDate</th>\n",
       "      <th>LastEditorUserId</th>\n",
       "      <th>CommunityOwnedDate</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>OwnerDisplayName</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>FavoriteCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2010-07-19T19:12:12.510</td>\n",
       "      <td>49</td>\n",
       "      <td>5466</td>\n",
       "      <td>&lt;p&gt;How should I elicit prior distributions fro...</td>\n",
       "      <td>8</td>\n",
       "      <td>2020-11-05T09:44:51.710</td>\n",
       "      <td>Eliciting priors from experts</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>CC BY-SA 2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>2010-07-19T19:12:57.157</td>\n",
       "      <td>34</td>\n",
       "      <td>33671</td>\n",
       "      <td>&lt;p&gt;In many different statistical methods there...</td>\n",
       "      <td>24</td>\n",
       "      <td>2022-11-23T13:03:42.033</td>\n",
       "      <td>What is normality?</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>CC BY-SA 2.5</td>\n",
       "      <td>user88</td>\n",
       "      <td>2010-08-07T17:56:44.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-07-19T19:13:28.577</td>\n",
       "      <td>71</td>\n",
       "      <td>6650</td>\n",
       "      <td>&lt;p&gt;What are some valuable Statistical Analysis...</td>\n",
       "      <td>18</td>\n",
       "      <td>2022-11-27T23:33:13.540</td>\n",
       "      <td>What are some valuable Statistical Analysis op...</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>CC BY-SA 2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-02-12T05:50:03.667</td>\n",
       "      <td>183</td>\n",
       "      <td>2010-07-19T19:13:28.577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>2010-07-19T19:13:31.617</td>\n",
       "      <td>23</td>\n",
       "      <td>45871</td>\n",
       "      <td>&lt;p&gt;I have two groups of data.  Each with a dif...</td>\n",
       "      <td>23</td>\n",
       "      <td>2010-09-08T03:00:19.690</td>\n",
       "      <td>Assessing the significance of differences in d...</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>CC BY-SA 2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-07-19T19:14:43.050</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;The R-project&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a href=\"http://www...</td>\n",
       "      <td>23</td>\n",
       "      <td>2010-07-19T19:21:15.063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>CC BY-SA 2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-07-19T19:21:15.063</td>\n",
       "      <td>23</td>\n",
       "      <td>2010-07-19T19:14:43.050</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411227</th>\n",
       "      <td>617792</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-03T21:10:44.450</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;I think any answers to this question will b...</td>\n",
       "      <td>2126</td>\n",
       "      <td>2023-06-03T21:21:51.590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-03T21:21:51.590</td>\n",
       "      <td>2126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>617771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411228</th>\n",
       "      <td>617793</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-03T23:12:10.920</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;p&gt;I have contradictory output when using R su...</td>\n",
       "      <td>389527</td>\n",
       "      <td>2023-06-04T00:13:02.877</td>\n",
       "      <td>R Survival Survreg Predict with \"response\" type</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-04T00:13:02.877</td>\n",
       "      <td>345611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411229</th>\n",
       "      <td>617794</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-03T23:31:23.367</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>&lt;p&gt;I have a simulated clinical data set that h...</td>\n",
       "      <td>216450</td>\n",
       "      <td>2023-06-03T23:31:23.367</td>\n",
       "      <td>MMRM not generating random slopes over time</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411230</th>\n",
       "      <td>617797</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-04T01:34:24.307</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;p&gt;There are many real-world phenomena in whic...</td>\n",
       "      <td>316764</td>\n",
       "      <td>2023-06-04T02:07:15.177</td>\n",
       "      <td>Are there conditions for which the Pareto dist...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-04T02:07:15.177</td>\n",
       "      <td>316764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411231</th>\n",
       "      <td>617798</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-04T03:21:51.860</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;p&gt;After differencing I saw that my constant/i...</td>\n",
       "      <td>373791</td>\n",
       "      <td>2023-06-04T04:02:50.557</td>\n",
       "      <td>python ARIMA remove intercept</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-04T04:02:50.557</td>\n",
       "      <td>373791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-04T05:03:43.637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411232 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id PostTypeId AcceptedAnswerId             CreationDate Score  \\\n",
       "0            1          1               15  2010-07-19T19:12:12.510    49   \n",
       "1            2          1               59  2010-07-19T19:12:57.157    34   \n",
       "2            3          1                5  2010-07-19T19:13:28.577    71   \n",
       "3            4          1              135  2010-07-19T19:13:31.617    23   \n",
       "4            5          2              NaN  2010-07-19T19:14:43.050    90   \n",
       "...        ...        ...              ...                      ...   ...   \n",
       "411227  617792          2              NaN  2023-06-03T21:10:44.450     4   \n",
       "411228  617793          1              NaN  2023-06-03T23:12:10.920     0   \n",
       "411229  617794          1              NaN  2023-06-03T23:31:23.367     0   \n",
       "411230  617797          1              NaN  2023-06-04T01:34:24.307     1   \n",
       "411231  617798          1              NaN  2023-06-04T03:21:51.860     0   \n",
       "\n",
       "       ViewCount                                               Body  \\\n",
       "0           5466  <p>How should I elicit prior distributions fro...   \n",
       "1          33671  <p>In many different statistical methods there...   \n",
       "2           6650  <p>What are some valuable Statistical Analysis...   \n",
       "3          45871  <p>I have two groups of data.  Each with a dif...   \n",
       "4            NaN  <p>The R-project</p>\\n\\n<p><a href=\"http://www...   \n",
       "...          ...                                                ...   \n",
       "411227       NaN  <p>I think any answers to this question will b...   \n",
       "411228         6  <p>I have contradictory output when using R su...   \n",
       "411229         7  <p>I have a simulated clinical data set that h...   \n",
       "411230         9  <p>There are many real-world phenomena in whic...   \n",
       "411231         5  <p>After differencing I saw that my constant/i...   \n",
       "\n",
       "       OwnerUserId         LastActivityDate  \\\n",
       "0                8  2020-11-05T09:44:51.710   \n",
       "1               24  2022-11-23T13:03:42.033   \n",
       "2               18  2022-11-27T23:33:13.540   \n",
       "3               23  2010-09-08T03:00:19.690   \n",
       "4               23  2010-07-19T19:21:15.063   \n",
       "...            ...                      ...   \n",
       "411227        2126  2023-06-03T21:21:51.590   \n",
       "411228      389527  2023-06-04T00:13:02.877   \n",
       "411229      216450  2023-06-03T23:31:23.367   \n",
       "411230      316764  2023-06-04T02:07:15.177   \n",
       "411231      373791  2023-06-04T04:02:50.557   \n",
       "\n",
       "                                                    Title  ... CommentCount  \\\n",
       "0                           Eliciting priors from experts  ...            1   \n",
       "1                                      What is normality?  ...            1   \n",
       "2       What are some valuable Statistical Analysis op...  ...            3   \n",
       "3       Assessing the significance of differences in d...  ...            2   \n",
       "4                                                     NaN  ...            3   \n",
       "...                                                   ...  ...          ...   \n",
       "411227                                                NaN  ...            1   \n",
       "411228    R Survival Survreg Predict with \"response\" type  ...            0   \n",
       "411229        MMRM not generating random slopes over time  ...            0   \n",
       "411230  Are there conditions for which the Pareto dist...  ...            0   \n",
       "411231                      python ARIMA remove intercept  ...            0   \n",
       "\n",
       "       ContentLicense LastEditorDisplayName             LastEditDate  \\\n",
       "0        CC BY-SA 2.5                   NaN                      NaN   \n",
       "1        CC BY-SA 2.5                user88  2010-08-07T17:56:44.800   \n",
       "2        CC BY-SA 2.5                   NaN  2011-02-12T05:50:03.667   \n",
       "3        CC BY-SA 2.5                   NaN                      NaN   \n",
       "4        CC BY-SA 2.5                   NaN  2010-07-19T19:21:15.063   \n",
       "...               ...                   ...                      ...   \n",
       "411227   CC BY-SA 4.0                   NaN  2023-06-03T21:21:51.590   \n",
       "411228   CC BY-SA 4.0                   NaN  2023-06-04T00:13:02.877   \n",
       "411229   CC BY-SA 4.0                   NaN                      NaN   \n",
       "411230   CC BY-SA 4.0                   NaN  2023-06-04T02:07:15.177   \n",
       "411231   CC BY-SA 4.0                   NaN  2023-06-04T04:02:50.557   \n",
       "\n",
       "       LastEditorUserId       CommunityOwnedDate ParentId OwnerDisplayName  \\\n",
       "0                   NaN                      NaN      NaN              NaN   \n",
       "1                   NaN                      NaN      NaN              NaN   \n",
       "2                   183  2010-07-19T19:13:28.577      NaN              NaN   \n",
       "3                   NaN                      NaN      NaN              NaN   \n",
       "4                    23  2010-07-19T19:14:43.050        3              NaN   \n",
       "...                 ...                      ...      ...              ...   \n",
       "411227             2126                      NaN   617771              NaN   \n",
       "411228           345611                      NaN      NaN              NaN   \n",
       "411229              NaN                      NaN      NaN              NaN   \n",
       "411230           316764                      NaN      NaN              NaN   \n",
       "411231           373791                      NaN      NaN              NaN   \n",
       "\n",
       "                     ClosedDate FavoriteCount  \n",
       "0                           NaN           NaN  \n",
       "1                           NaN           NaN  \n",
       "2                           NaN           NaN  \n",
       "3                           NaN           NaN  \n",
       "4                           NaN           NaN  \n",
       "...                         ...           ...  \n",
       "411227                      NaN           NaN  \n",
       "411228                      NaN           NaN  \n",
       "411229                      NaN           NaN  \n",
       "411230                      NaN           NaN  \n",
       "411231  2023-06-04T05:03:43.637           NaN  \n",
       "\n",
       "[411232 rows x 22 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load the XML file\n",
    "tree = ET.parse('Posts.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# Define a list to store the data\n",
    "data = []\n",
    "\n",
    "# Extract data from XML and store it in the list\n",
    "for row in root.findall('row'):\n",
    "    row_data = row.attrib\n",
    "    data.append(row_data)\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203832"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tags'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<bayesian><prior><elicitation>',\n",
       "       '<distributions><normality-assumption>', '<software><open-source>',\n",
       "       ..., '<regression><survival><predictive-models>',\n",
       "       '<distributions><central-limit-theorem><pareto-distribution>',\n",
       "       '<statistical-significance><python><arima><intercept>'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tags'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>Body</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>LastActivityDate</th>\n",
       "      <th>Title</th>\n",
       "      <th>...</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>ContentLicense</th>\n",
       "      <th>LastEditorDisplayName</th>\n",
       "      <th>LastEditDate</th>\n",
       "      <th>LastEditorUserId</th>\n",
       "      <th>CommunityOwnedDate</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>OwnerDisplayName</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>FavoriteCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2010-07-19T19:12:12.510</td>\n",
       "      <td>49</td>\n",
       "      <td>5466</td>\n",
       "      <td>&lt;p&gt;How should I elicit prior distributions fro...</td>\n",
       "      <td>8</td>\n",
       "      <td>2020-11-05T09:44:51.710</td>\n",
       "      <td>Eliciting priors from experts</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>CC BY-SA 2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>2010-07-19T19:12:57.157</td>\n",
       "      <td>34</td>\n",
       "      <td>33671</td>\n",
       "      <td>&lt;p&gt;In many different statistical methods there...</td>\n",
       "      <td>24</td>\n",
       "      <td>2022-11-23T13:03:42.033</td>\n",
       "      <td>What is normality?</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>CC BY-SA 2.5</td>\n",
       "      <td>user88</td>\n",
       "      <td>2010-08-07T17:56:44.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-07-19T19:13:28.577</td>\n",
       "      <td>71</td>\n",
       "      <td>6650</td>\n",
       "      <td>&lt;p&gt;What are some valuable Statistical Analysis...</td>\n",
       "      <td>18</td>\n",
       "      <td>2022-11-27T23:33:13.540</td>\n",
       "      <td>What are some valuable Statistical Analysis op...</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>CC BY-SA 2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-02-12T05:50:03.667</td>\n",
       "      <td>183</td>\n",
       "      <td>2010-07-19T19:13:28.577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>2010-07-19T19:13:31.617</td>\n",
       "      <td>23</td>\n",
       "      <td>45871</td>\n",
       "      <td>&lt;p&gt;I have two groups of data.  Each with a dif...</td>\n",
       "      <td>23</td>\n",
       "      <td>2010-09-08T03:00:19.690</td>\n",
       "      <td>Assessing the significance of differences in d...</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>CC BY-SA 2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-07-19T19:14:44.080</td>\n",
       "      <td>486</td>\n",
       "      <td>173164</td>\n",
       "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=...</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-01-19T17:59:15.653</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learn...</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-08T17:58:18.247</td>\n",
       "      <td>11887</td>\n",
       "      <td>2010-08-09T13:05:50.603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411226</th>\n",
       "      <td>617791</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-03T21:06:31.243</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;p&gt;Let's say I want to flip a coin a billion t...</td>\n",
       "      <td>353918</td>\n",
       "      <td>2023-06-03T21:06:31.243</td>\n",
       "      <td>Simulating the outcome of X number of random t...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411228</th>\n",
       "      <td>617793</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-03T23:12:10.920</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;p&gt;I have contradictory output when using R su...</td>\n",
       "      <td>389527</td>\n",
       "      <td>2023-06-04T00:13:02.877</td>\n",
       "      <td>R Survival Survreg Predict with \"response\" type</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-04T00:13:02.877</td>\n",
       "      <td>345611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411229</th>\n",
       "      <td>617794</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-03T23:31:23.367</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>&lt;p&gt;I have a simulated clinical data set that h...</td>\n",
       "      <td>216450</td>\n",
       "      <td>2023-06-03T23:31:23.367</td>\n",
       "      <td>MMRM not generating random slopes over time</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411230</th>\n",
       "      <td>617797</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-04T01:34:24.307</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;p&gt;There are many real-world phenomena in whic...</td>\n",
       "      <td>316764</td>\n",
       "      <td>2023-06-04T02:07:15.177</td>\n",
       "      <td>Are there conditions for which the Pareto dist...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-04T02:07:15.177</td>\n",
       "      <td>316764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411231</th>\n",
       "      <td>617798</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-04T03:21:51.860</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;p&gt;After differencing I saw that my constant/i...</td>\n",
       "      <td>373791</td>\n",
       "      <td>2023-06-04T04:02:50.557</td>\n",
       "      <td>python ARIMA remove intercept</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-04T04:02:50.557</td>\n",
       "      <td>373791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-04T05:03:43.637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207400 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id PostTypeId AcceptedAnswerId             CreationDate Score  \\\n",
       "0            1          1               15  2010-07-19T19:12:12.510    49   \n",
       "1            2          1               59  2010-07-19T19:12:57.157    34   \n",
       "2            3          1                5  2010-07-19T19:13:28.577    71   \n",
       "3            4          1              135  2010-07-19T19:13:31.617    23   \n",
       "5            6          1              NaN  2010-07-19T19:14:44.080   486   \n",
       "...        ...        ...              ...                      ...   ...   \n",
       "411226  617791          1              NaN  2023-06-03T21:06:31.243     0   \n",
       "411228  617793          1              NaN  2023-06-03T23:12:10.920     0   \n",
       "411229  617794          1              NaN  2023-06-03T23:31:23.367     0   \n",
       "411230  617797          1              NaN  2023-06-04T01:34:24.307     1   \n",
       "411231  617798          1              NaN  2023-06-04T03:21:51.860     0   \n",
       "\n",
       "       ViewCount                                               Body  \\\n",
       "0           5466  <p>How should I elicit prior distributions fro...   \n",
       "1          33671  <p>In many different statistical methods there...   \n",
       "2           6650  <p>What are some valuable Statistical Analysis...   \n",
       "3          45871  <p>I have two groups of data.  Each with a dif...   \n",
       "5         173164  <p>Last year, I read a blog post from <a href=...   \n",
       "...          ...                                                ...   \n",
       "411226         6  <p>Let's say I want to flip a coin a billion t...   \n",
       "411228         6  <p>I have contradictory output when using R su...   \n",
       "411229         7  <p>I have a simulated clinical data set that h...   \n",
       "411230         9  <p>There are many real-world phenomena in whic...   \n",
       "411231         5  <p>After differencing I saw that my constant/i...   \n",
       "\n",
       "       OwnerUserId         LastActivityDate  \\\n",
       "0                8  2020-11-05T09:44:51.710   \n",
       "1               24  2022-11-23T13:03:42.033   \n",
       "2               18  2022-11-27T23:33:13.540   \n",
       "3               23  2010-09-08T03:00:19.690   \n",
       "5                5  2021-01-19T17:59:15.653   \n",
       "...            ...                      ...   \n",
       "411226      353918  2023-06-03T21:06:31.243   \n",
       "411228      389527  2023-06-04T00:13:02.877   \n",
       "411229      216450  2023-06-03T23:31:23.367   \n",
       "411230      316764  2023-06-04T02:07:15.177   \n",
       "411231      373791  2023-06-04T04:02:50.557   \n",
       "\n",
       "                                                    Title  ... CommentCount  \\\n",
       "0                           Eliciting priors from experts  ...            1   \n",
       "1                                      What is normality?  ...            1   \n",
       "2       What are some valuable Statistical Analysis op...  ...            3   \n",
       "3       Assessing the significance of differences in d...  ...            2   \n",
       "5       The Two Cultures: statistics vs. machine learn...  ...           10   \n",
       "...                                                   ...  ...          ...   \n",
       "411226  Simulating the outcome of X number of random t...  ...            1   \n",
       "411228    R Survival Survreg Predict with \"response\" type  ...            0   \n",
       "411229        MMRM not generating random slopes over time  ...            0   \n",
       "411230  Are there conditions for which the Pareto dist...  ...            0   \n",
       "411231                      python ARIMA remove intercept  ...            0   \n",
       "\n",
       "       ContentLicense LastEditorDisplayName             LastEditDate  \\\n",
       "0        CC BY-SA 2.5                   NaN                      NaN   \n",
       "1        CC BY-SA 2.5                user88  2010-08-07T17:56:44.800   \n",
       "2        CC BY-SA 2.5                   NaN  2011-02-12T05:50:03.667   \n",
       "3        CC BY-SA 2.5                   NaN                      NaN   \n",
       "5        CC BY-SA 3.0                   NaN  2017-04-08T17:58:18.247   \n",
       "...               ...                   ...                      ...   \n",
       "411226   CC BY-SA 4.0                   NaN                      NaN   \n",
       "411228   CC BY-SA 4.0                   NaN  2023-06-04T00:13:02.877   \n",
       "411229   CC BY-SA 4.0                   NaN                      NaN   \n",
       "411230   CC BY-SA 4.0                   NaN  2023-06-04T02:07:15.177   \n",
       "411231   CC BY-SA 4.0                   NaN  2023-06-04T04:02:50.557   \n",
       "\n",
       "       LastEditorUserId       CommunityOwnedDate ParentId OwnerDisplayName  \\\n",
       "0                   NaN                      NaN      NaN              NaN   \n",
       "1                   NaN                      NaN      NaN              NaN   \n",
       "2                   183  2010-07-19T19:13:28.577      NaN              NaN   \n",
       "3                   NaN                      NaN      NaN              NaN   \n",
       "5                 11887  2010-08-09T13:05:50.603      NaN              NaN   \n",
       "...                 ...                      ...      ...              ...   \n",
       "411226              NaN                      NaN      NaN              NaN   \n",
       "411228           345611                      NaN      NaN              NaN   \n",
       "411229              NaN                      NaN      NaN              NaN   \n",
       "411230           316764                      NaN      NaN              NaN   \n",
       "411231           373791                      NaN      NaN              NaN   \n",
       "\n",
       "                     ClosedDate FavoriteCount  \n",
       "0                           NaN           NaN  \n",
       "1                           NaN           NaN  \n",
       "2                           NaN           NaN  \n",
       "3                           NaN           NaN  \n",
       "5                           NaN           NaN  \n",
       "...                         ...           ...  \n",
       "411226                      NaN           NaN  \n",
       "411228                      NaN           NaN  \n",
       "411229                      NaN           NaN  \n",
       "411230                      NaN           NaN  \n",
       "411231  2023-06-04T05:03:43.637           NaN  \n",
       "\n",
       "[207400 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Body','Tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;How should I elicit prior distributions fro...</td>\n",
       "      <td>&lt;bayesian&gt;&lt;prior&gt;&lt;elicitation&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;In many different statistical methods there...</td>\n",
       "      <td>&lt;distributions&gt;&lt;normality-assumption&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;What are some valuable Statistical Analysis...</td>\n",
       "      <td>&lt;software&gt;&lt;open-source&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p&gt;I have two groups of data.  Each with a dif...</td>\n",
       "      <td>&lt;distributions&gt;&lt;statistical-significance&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=...</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;pac-learning&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411226</th>\n",
       "      <td>&lt;p&gt;Let's say I want to flip a coin a billion t...</td>\n",
       "      <td>&lt;probability&gt;&lt;random-variable&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411228</th>\n",
       "      <td>&lt;p&gt;I have contradictory output when using R su...</td>\n",
       "      <td>&lt;regression&gt;&lt;survival&gt;&lt;predictive-models&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411229</th>\n",
       "      <td>&lt;p&gt;I have a simulated clinical data set that h...</td>\n",
       "      <td>&lt;r&gt;&lt;mixed-model&gt;&lt;clinical-trials&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411230</th>\n",
       "      <td>&lt;p&gt;There are many real-world phenomena in whic...</td>\n",
       "      <td>&lt;distributions&gt;&lt;central-limit-theorem&gt;&lt;pareto-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411231</th>\n",
       "      <td>&lt;p&gt;After differencing I saw that my constant/i...</td>\n",
       "      <td>&lt;statistical-significance&gt;&lt;python&gt;&lt;arima&gt;&lt;inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Body  \\\n",
       "0       <p>How should I elicit prior distributions fro...   \n",
       "1       <p>In many different statistical methods there...   \n",
       "2       <p>What are some valuable Statistical Analysis...   \n",
       "3       <p>I have two groups of data.  Each with a dif...   \n",
       "5       <p>Last year, I read a blog post from <a href=...   \n",
       "...                                                   ...   \n",
       "411226  <p>Let's say I want to flip a coin a billion t...   \n",
       "411228  <p>I have contradictory output when using R su...   \n",
       "411229  <p>I have a simulated clinical data set that h...   \n",
       "411230  <p>There are many real-world phenomena in whic...   \n",
       "411231  <p>After differencing I saw that my constant/i...   \n",
       "\n",
       "                                                     Tags  \n",
       "0                          <bayesian><prior><elicitation>  \n",
       "1                   <distributions><normality-assumption>  \n",
       "2                                 <software><open-source>  \n",
       "3               <distributions><statistical-significance>  \n",
       "5                        <machine-learning><pac-learning>  \n",
       "...                                                   ...  \n",
       "411226                     <probability><random-variable>  \n",
       "411228          <regression><survival><predictive-models>  \n",
       "411229                  <r><mixed-model><clinical-trials>  \n",
       "411230  <distributions><central-limit-theorem><pareto-...  \n",
       "411231  <statistical-significance><python><arima><inte...  \n",
       "\n",
       "[207400 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove special characters and symbols\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove new lines\n",
    "    text = text.replace('\\n', '')\n",
    "    \n",
    "    # lower case the input\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special pattern\n",
    "    substring_to_remove = '\\\\'\n",
    "    words = text.split()\n",
    "    cleaned_words = [word for word in words if substring_to_remove not in word]\n",
    "    text = ' '.join(cleaned_words)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-7232e2e19162>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Body'] = df['Body'].apply(clean_text)\n"
     ]
    }
   ],
   "source": [
    "df['Body'] = df['Body'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = []\n",
    "for i in df['Body']:\n",
    "    lens.append(len(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "940.3282497589199"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i know this must be standard material but i had difficulty in finding a proof in this formlet e be a standard white gaussian vector of size n let all the other matrices in the following be constantlet v xy e where x is an ntimes l matrix and y is an ntimes 1 vector and letleftbeginalign bar y amp xtx1xtv bar e amp v xbar y endalignrightquadif c is any constant vector j n mathrmrankx and leftbeginalign u amp ctbar y s2 amp bar etbar ectxtx1c endalignrightquadthen the random variable defined as t usqrts2j follows a normalized students t distribution with j degrees of freedomi would be grateful if you could provide an outline for its proof'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Body'].iloc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how should i elicit prior distributions from e...</td>\n",
       "      <td>&lt;bayesian&gt;&lt;prior&gt;&lt;elicitation&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in many different statistical methods there is...</td>\n",
       "      <td>&lt;distributions&gt;&lt;normality-assumption&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what are some valuable statistical analysis op...</td>\n",
       "      <td>&lt;software&gt;&lt;open-source&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have two groups of data each with a differen...</td>\n",
       "      <td>&lt;distributions&gt;&lt;statistical-significance&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>last year i read a blog post from brendan ocon...</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;pac-learning&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411226</th>\n",
       "      <td>lets say i want to flip a coin a billion times...</td>\n",
       "      <td>&lt;probability&gt;&lt;random-variable&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411228</th>\n",
       "      <td>i have contradictory output when using r survi...</td>\n",
       "      <td>&lt;regression&gt;&lt;survival&gt;&lt;predictive-models&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411229</th>\n",
       "      <td>i have a simulated clinical data set that has ...</td>\n",
       "      <td>&lt;r&gt;&lt;mixed-model&gt;&lt;clinical-trials&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411230</th>\n",
       "      <td>there are many realworld phenomena in which a ...</td>\n",
       "      <td>&lt;distributions&gt;&lt;central-limit-theorem&gt;&lt;pareto-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411231</th>\n",
       "      <td>after differencing i saw that my constantinter...</td>\n",
       "      <td>&lt;statistical-significance&gt;&lt;python&gt;&lt;arima&gt;&lt;inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Body  \\\n",
       "0       how should i elicit prior distributions from e...   \n",
       "1       in many different statistical methods there is...   \n",
       "2       what are some valuable statistical analysis op...   \n",
       "3       i have two groups of data each with a differen...   \n",
       "5       last year i read a blog post from brendan ocon...   \n",
       "...                                                   ...   \n",
       "411226  lets say i want to flip a coin a billion times...   \n",
       "411228  i have contradictory output when using r survi...   \n",
       "411229  i have a simulated clinical data set that has ...   \n",
       "411230  there are many realworld phenomena in which a ...   \n",
       "411231  after differencing i saw that my constantinter...   \n",
       "\n",
       "                                                     Tags  \n",
       "0                          <bayesian><prior><elicitation>  \n",
       "1                   <distributions><normality-assumption>  \n",
       "2                                 <software><open-source>  \n",
       "3               <distributions><statistical-significance>  \n",
       "5                        <machine-learning><pac-learning>  \n",
       "...                                                   ...  \n",
       "411226                     <probability><random-variable>  \n",
       "411228          <regression><survival><predictive-models>  \n",
       "411229                  <r><mixed-model><clinical-trials>  \n",
       "411230  <distributions><central-limit-theorem><pareto-...  \n",
       "411231  <statistical-significance><python><arima><inte...  \n",
       "\n",
       "[207400 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            <bayesian><prior><elicitation>\n",
       "1                     <distributions><normality-assumption>\n",
       "2                                   <software><open-source>\n",
       "3                 <distributions><statistical-significance>\n",
       "5                          <machine-learning><pac-learning>\n",
       "                                ...                        \n",
       "411226                       <probability><random-variable>\n",
       "411228            <regression><survival><predictive-models>\n",
       "411229                    <r><mixed-model><clinical-trials>\n",
       "411230    <distributions><central-limit-theorem><pareto-...\n",
       "411231    <statistical-significance><python><arima><inte...\n",
       "Name: Tags, Length: 207400, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how should i elicit prior distributions from e...</td>\n",
       "      <td>&lt;bayesian&gt;&lt;prior&gt;&lt;elicitation&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in many different statistical methods there is...</td>\n",
       "      <td>&lt;distributions&gt;&lt;normality-assumption&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what are some valuable statistical analysis op...</td>\n",
       "      <td>&lt;software&gt;&lt;open-source&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have two groups of data each with a differen...</td>\n",
       "      <td>&lt;distributions&gt;&lt;statistical-significance&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>last year i read a blog post from brendan ocon...</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;pac-learning&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411226</th>\n",
       "      <td>lets say i want to flip a coin a billion times...</td>\n",
       "      <td>&lt;probability&gt;&lt;random-variable&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411228</th>\n",
       "      <td>i have contradictory output when using r survi...</td>\n",
       "      <td>&lt;regression&gt;&lt;survival&gt;&lt;predictive-models&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411229</th>\n",
       "      <td>i have a simulated clinical data set that has ...</td>\n",
       "      <td>&lt;r&gt;&lt;mixed-model&gt;&lt;clinical-trials&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411230</th>\n",
       "      <td>there are many realworld phenomena in which a ...</td>\n",
       "      <td>&lt;distributions&gt;&lt;central-limit-theorem&gt;&lt;pareto-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411231</th>\n",
       "      <td>after differencing i saw that my constantinter...</td>\n",
       "      <td>&lt;statistical-significance&gt;&lt;python&gt;&lt;arima&gt;&lt;inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Body  \\\n",
       "0       how should i elicit prior distributions from e...   \n",
       "1       in many different statistical methods there is...   \n",
       "2       what are some valuable statistical analysis op...   \n",
       "3       i have two groups of data each with a differen...   \n",
       "5       last year i read a blog post from brendan ocon...   \n",
       "...                                                   ...   \n",
       "411226  lets say i want to flip a coin a billion times...   \n",
       "411228  i have contradictory output when using r survi...   \n",
       "411229  i have a simulated clinical data set that has ...   \n",
       "411230  there are many realworld phenomena in which a ...   \n",
       "411231  after differencing i saw that my constantinter...   \n",
       "\n",
       "                                                     Tags  \n",
       "0                          <bayesian><prior><elicitation>  \n",
       "1                   <distributions><normality-assumption>  \n",
       "2                                 <software><open-source>  \n",
       "3               <distributions><statistical-significance>  \n",
       "5                        <machine-learning><pac-learning>  \n",
       "...                                                   ...  \n",
       "411226                     <probability><random-variable>  \n",
       "411228          <regression><survival><predictive-models>  \n",
       "411229                  <r><mixed-model><clinical-trials>  \n",
       "411230  <distributions><central-limit-theorem><pareto-...  \n",
       "411231  <statistical-significance><python><arima><inte...  \n",
       "\n",
       "[207400 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_list(tag_string):\n",
    "        return tag_string.split(' ')\n",
    "def prepare_tags(df):\n",
    "    import re\n",
    "\n",
    "    df['Tags'] = df['Tags'].apply(lambda x: re.findall(r'<(\\w+[-\\w+]*)>', x))\n",
    "    # Combine tags into a single string\n",
    "    df['TagString'] = df['Tags'].apply(lambda x: ' '.join(x))\n",
    "    df.drop('Tags',axis=1,inplace=True)\n",
    "    \n",
    "    # Apply the function to the 'TagString' column\n",
    "    df['TagString'] = df['TagString'].apply(lambda x: convert_to_list(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-1c25d81e5fc5>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tags'] = df['Tags'].apply(lambda x: re.findall(r'<(\\w+[-\\w+]*)>', x))\n",
      "<ipython-input-16-1c25d81e5fc5>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TagString'] = df['Tags'].apply(lambda x: ' '.join(x))\n",
      "<ipython-input-16-1c25d81e5fc5>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop('Tags',axis=1,inplace=True)\n",
      "<ipython-input-16-1c25d81e5fc5>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TagString'] = df['TagString'].apply(lambda x: convert_to_list(x))\n"
     ]
    }
   ],
   "source": [
    "prepare_tags(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>TagString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how should i elicit prior distributions from e...</td>\n",
       "      <td>[bayesian, prior, elicitation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in many different statistical methods there is...</td>\n",
       "      <td>[distributions, normality-assumption]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what are some valuable statistical analysis op...</td>\n",
       "      <td>[software, open-source]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have two groups of data each with a differen...</td>\n",
       "      <td>[distributions, statistical-significance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>last year i read a blog post from brendan ocon...</td>\n",
       "      <td>[machine-learning, pac-learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411226</th>\n",
       "      <td>lets say i want to flip a coin a billion times...</td>\n",
       "      <td>[probability, random-variable]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411228</th>\n",
       "      <td>i have contradictory output when using r survi...</td>\n",
       "      <td>[regression, survival, predictive-models]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411229</th>\n",
       "      <td>i have a simulated clinical data set that has ...</td>\n",
       "      <td>[r, mixed-model, clinical-trials]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411230</th>\n",
       "      <td>there are many realworld phenomena in which a ...</td>\n",
       "      <td>[distributions, central-limit-theorem, pareto-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411231</th>\n",
       "      <td>after differencing i saw that my constantinter...</td>\n",
       "      <td>[statistical-significance, python, arima, inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Body  \\\n",
       "0       how should i elicit prior distributions from e...   \n",
       "1       in many different statistical methods there is...   \n",
       "2       what are some valuable statistical analysis op...   \n",
       "3       i have two groups of data each with a differen...   \n",
       "5       last year i read a blog post from brendan ocon...   \n",
       "...                                                   ...   \n",
       "411226  lets say i want to flip a coin a billion times...   \n",
       "411228  i have contradictory output when using r survi...   \n",
       "411229  i have a simulated clinical data set that has ...   \n",
       "411230  there are many realworld phenomena in which a ...   \n",
       "411231  after differencing i saw that my constantinter...   \n",
       "\n",
       "                                                TagString  \n",
       "0                          [bayesian, prior, elicitation]  \n",
       "1                   [distributions, normality-assumption]  \n",
       "2                                 [software, open-source]  \n",
       "3               [distributions, statistical-significance]  \n",
       "5                        [machine-learning, pac-learning]  \n",
       "...                                                   ...  \n",
       "411226                     [probability, random-variable]  \n",
       "411228          [regression, survival, predictive-models]  \n",
       "411229                  [r, mixed-model, clinical-trials]  \n",
       "411230  [distributions, central-limit-theorem, pareto-...  \n",
       "411231  [statistical-significance, python, arima, inte...  \n",
       "\n",
       "[207400 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "bar",
         "x": [
          "r",
          "regression",
          "machine-learning",
          "time-series",
          "probability",
          "hypothesis-testing",
          "distributions",
          "self-study",
          "neural-networks",
          "bayesian",
          "logistic",
          "mathematical-statistics",
          "classification",
          "correlation",
          "statistical-significance",
          "mixed-model",
          "normal-distribution",
          "multiple-regression",
          "anova",
          "python",
          "confidence-interval",
          "generalized-linear-model",
          "variance",
          "clustering",
          "forecasting"
         ],
         "y": [
          28881,
          28597,
          19672,
          13951,
          12103,
          10286,
          9278,
          8081,
          7883,
          7757,
          7605,
          7565,
          6736,
          6149,
          6133,
          5962,
          5955,
          5345,
          5144,
          4681,
          4433,
          4349,
          4116,
          3948,
          3783
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Top 25 Frequent Tags"
        },
        "xaxis": {
         "title": {
          "text": "Tag"
         }
        },
        "yaxis": {
         "title": {
          "text": "Frequency"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"6bf5148e-bf27-466c-8967-22e20d93c16c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6bf5148e-bf27-466c-8967-22e20d93c16c\")) {                    Plotly.newPlot(                        \"6bf5148e-bf27-466c-8967-22e20d93c16c\",                        [{\"x\":[\"r\",\"regression\",\"machine-learning\",\"time-series\",\"probability\",\"hypothesis-testing\",\"distributions\",\"self-study\",\"neural-networks\",\"bayesian\",\"logistic\",\"mathematical-statistics\",\"classification\",\"correlation\",\"statistical-significance\",\"mixed-model\",\"normal-distribution\",\"multiple-regression\",\"anova\",\"python\",\"confidence-interval\",\"generalized-linear-model\",\"variance\",\"clustering\",\"forecasting\"],\"y\":[28881,28597,19672,13951,12103,10286,9278,8081,7883,7757,7605,7565,6736,6149,6133,5962,5955,5345,5144,4681,4433,4349,4116,3948,3783],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Top 25 Frequent Tags\"},\"xaxis\":{\"title\":{\"text\":\"Tag\"}},\"yaxis\":{\"title\":{\"text\":\"Frequency\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('6bf5148e-bf27-466c-8967-22e20d93c16c');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming you have a DataFrame called `df` with the `TagString` feature\n",
    "\n",
    "# Count the frequency of each tag\n",
    "tag_counts = Counter([tag for tags in df['TagString'] for tag in tags])\n",
    "\n",
    "# Get the top 25 frequent tags and their frequencies\n",
    "top_tags = tag_counts.most_common(25)\n",
    "tags, frequencies = zip(*top_tags)\n",
    "\n",
    "# Create a bar plot using Plotly\n",
    "fig = go.Figure(data=go.Bar(x=tags, y=frequencies))\n",
    "fig.update_layout(title='Top 25 Frequent Tags', xaxis_title='Tag', yaxis_title='Frequency')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-07f5a68d4651>:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter the TagString feature\n",
    "top_words = []\n",
    "for i in top_tags:\n",
    "\n",
    "    top_words.append(i[0])\n",
    "filtered = df[df['TagString'].apply(lambda x: any(word in x for word in top_words))]\n",
    "filtered['TagString'] = [[tag for tag in tag_list if tag in top_words] for tag_list in filtered['TagString']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Create an instance of MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit and transform the 'TagString' column\n",
    "y = mlb.fit_transform(filtered['TagString'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.to_csv('dataset_v1_25_tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>TagString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how should i elicit prior distributions from e...</td>\n",
       "      <td>[bayesian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in many different statistical methods there is...</td>\n",
       "      <td>[distributions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have two groups of data each with a differen...</td>\n",
       "      <td>[distributions, statistical-significance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>last year i read a blog post from brendan ocon...</td>\n",
       "      <td>[machine-learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>i have four competing models which i use to pr...</td>\n",
       "      <td>[anova, generalized-linear-model]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411226</th>\n",
       "      <td>lets say i want to flip a coin a billion times...</td>\n",
       "      <td>[probability]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411228</th>\n",
       "      <td>i have contradictory output when using r survi...</td>\n",
       "      <td>[regression]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411229</th>\n",
       "      <td>i have a simulated clinical data set that has ...</td>\n",
       "      <td>[r, mixed-model]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411230</th>\n",
       "      <td>there are many realworld phenomena in which a ...</td>\n",
       "      <td>[distributions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411231</th>\n",
       "      <td>after differencing i saw that my constantinter...</td>\n",
       "      <td>[statistical-significance, python]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149274 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Body  \\\n",
       "0       how should i elicit prior distributions from e...   \n",
       "1       in many different statistical methods there is...   \n",
       "3       i have two groups of data each with a differen...   \n",
       "5       last year i read a blog post from brendan ocon...   \n",
       "15      i have four competing models which i use to pr...   \n",
       "...                                                   ...   \n",
       "411226  lets say i want to flip a coin a billion times...   \n",
       "411228  i have contradictory output when using r survi...   \n",
       "411229  i have a simulated clinical data set that has ...   \n",
       "411230  there are many realworld phenomena in which a ...   \n",
       "411231  after differencing i saw that my constantinter...   \n",
       "\n",
       "                                        TagString  \n",
       "0                                      [bayesian]  \n",
       "1                                 [distributions]  \n",
       "3       [distributions, statistical-significance]  \n",
       "5                              [machine-learning]  \n",
       "15              [anova, generalized-linear-model]  \n",
       "...                                           ...  \n",
       "411226                              [probability]  \n",
       "411228                               [regression]  \n",
       "411229                           [r, mixed-model]  \n",
       "411230                            [distributions]  \n",
       "411231         [statistical-significance, python]  \n",
       "\n",
       "[149274 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149274, 25)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tags[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = []\n",
    "for i in top_tags:\n",
    "\n",
    "    top_words.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter the TagString feature\n",
    "filtered = df[df['TagString'].apply(lambda x: any(word in x for word in top_words))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered['TagString'] = [[tag for tag in tag_list if tag in top_words] for tag_list in filtered['TagString']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_map = {}\n",
    "idx = 0\n",
    "for i in tags:\n",
    "    word_map[i] = idx\n",
    "    idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['TagString'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered['TagString'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Convert TagString column to a list of lists\n",
    "tag_lists = [tags for tags in filtered['TagString']]\n",
    "\n",
    "# Create an instance of MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit and transform the tag lists\n",
    "y = mlb.fit_transform(tag_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = filtered.sample(frac=0.3, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(filtered['Body'],y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[0], y_train[0], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mlb.inverse_transform(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tfidf_features(X_train, X_test):\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=200,max_df=0.9,ngram_range=(1,2),token_pattern= '(\\S+)')\n",
    "    X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "    X_test = tfidf_vectorizer.transform(X_test)\n",
    "    return X_train, X_test, tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = train_df['Body']\n",
    "#y_train = train_df['TagString']\n",
    "#X_val = test_df ['Body']\n",
    "#y_val = test_df ['TagString']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, tfidf_vocab = tfidf_features(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "#model.add(InputLayer(input_shape=(x_train.shape[1],)))  # Remove sparse=True\n",
    "#model.add(Reshape((x_train.shape[1], 1)))\n",
    "#model.add(Conv1D(filters=32, kernel_size=3,strides=2, activation='leaky_relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Conv1D(filters=16, kernel_size=3,strides=2, activation='leaky_relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Conv1D(filters=8, kernel_size=3,strides=1, activation='leaky_relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Conv1D(filters=4, kernel_size=3,strides=1, activation='leaky_relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Conv1D(filters=1, kernel_size=3,strides=1, activation='leaky_relu'))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "#model.add(Dense(128, activation='leaky_relu'))\n",
    "#model.add(Dense(64, activation='leaky_relu'))\n",
    "#model.add(Dense(50, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,InputLayer,Conv2D, BatchNormalization, Reshape, Conv1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(x_train.shape[1],)))  # Remove sparse=True\n",
    "model.add(Reshape((x_train.shape[1], 1)))\n",
    "model.add(Conv1D(filters=32, kernel_size=3,strides=2, activation='leaky_relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=16, kernel_size=3,strides=2, activation='leaky_relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=8, kernel_size=3,strides=1, activation='leaky_relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=4, kernel_size=3,strides=1, activation='leaky_relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=1, kernel_size=3,strides=1, activation='leaky_relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Reshape((1751,)))\n",
    "\n",
    "model.add(Dense(128, activation='leaky_relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation='leaky_relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(50, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path = 'trained_model.h5'\n",
    "# Load the saved model\n",
    "loaded_model = load_model(model_path)\n",
    "\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train.toarray(), y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'trained_model.h5'\n",
    "\n",
    "# Save the model\n",
    "model.save(model_path)\n",
    "\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights[0] - model2.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_path = 'model_checkpoint.h5'\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    save_best_only=True,  # Save only the best model\n",
    "    save_weights_only=True,  # Save only the weights\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train.toarray(), y_train, epochs=40, batch_size=32, callbacks=[checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 0.0190\n",
    "best_test_loss = 0.0215"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train_sparse = tf.sparse.from_dense(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test.toarray(),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(prediction[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred = np.where(prediction >= 0.1, 1, 0)\n",
    "\n",
    "# Print the thresholded predictions\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_pred,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the predictions stored in y_pred\n",
    "y_pred_inverse = mlb.inverse_transform(y_pred)\n",
    "\n",
    "# Print the inverse transformed predictions\n",
    "idx = 0\n",
    "for tags in y_pred_inverse:\n",
    "    print('Predicted Tag: ',tags, 'Actual Tag', lol[idx])\n",
    "    print('-----')\n",
    "    idx = idx + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = mlb.inverse_transform(y_test)\n",
    "# Print the inverse transformed predictions\n",
    "for tags in lol:\n",
    "    print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_try = x_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_try.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data_interviews_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = df_test['Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = [text_prepare(text) for text in x_pred ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the stop words and stemmer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words and convert to lowercase\n",
    "    tokens = [token.lower() for token in tokens if token.lower() not in stop_words]\n",
    "    \n",
    "    # Perform stemming\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Join the tokens back into a single string\n",
    "    preprocessed_text = ' '.join(stemmed_tokens)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred =  [preprocess_text(x) for x in x_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_pred, tfidf_vocab = tfidf_features(X_train, x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x_pred.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred = np.where(prediction >= 0.01, 1, 0)\n",
    "\n",
    "# Print the thresholded predictions\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the predictions stored in y_pred\n",
    "y_pred_inverse = mlb.inverse_transform(y_pred)\n",
    "\n",
    "# Print the inverse transformed predictions\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred_inverse[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_inverse[0].contains(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for i in y_pred_inverse:\n",
    "    if(len(i)>0 and ('references' not in i and len(i)==1)):\n",
    "        print('Question:', df_test['Question'][idx], \n",
    "             'Tag: ', i)\n",
    "        idx = idx + 1\n",
    "        print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = list(y_pred_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = [list(y) for y in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_remove = ['references', 'self-study']\n",
    "\n",
    "# Remove specific values from each list\n",
    "updated_list_of_lists = [[item for item in sublist if item not in values_to_remove] for sublist in y_pred_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_list_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags = pd.DataFrame(updated_list_of_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags = pd.DataFrame({'Tags': updated_list_of_lists})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Tags'] = df_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for i in df_test['Tags']:\n",
    "    if (len(i)>1):\n",
    "        cnt = cnt + 1\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('tagged_v1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train_bin = mlb.fit_transform(y_train)\n",
    "    \n",
    "def train_classifier(X_train, y_train, penalty):\n",
    "    # Convert the labels to binary array representation\n",
    "    \n",
    "    \n",
    "    # Train the classifier\n",
    "    model = OneVsRestClassifier(LogisticRegression(penalty=penalty))\n",
    "    model.fit(X_train, y_train_bin)       \n",
    "    return model\n",
    "\n",
    "# Train the classifier\n",
    "classifier_tfidf_l2 = train_classifier(X_train_tfidf, y_train, 'l2')\n",
    "\n",
    "# Convert the validation labels to binary array representation\n",
    "y_val_bin = mlb.transform(y_val)\n",
    "\n",
    "# Predict and obtain scores\n",
    "y_val_predicted_labels_tfidf_l2 = classifier_tfidf_l2.predict(X_val_tfidf)\n",
    "y_val_predicted_scores_tfidf_l2 = classifier_tfidf_l2.decision_function(X_val_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tags = mlb.inverse_transform(y_val_predicted_labels_tfidf_l2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val[1:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tags[2], X_val.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "def print_evaluation_scores(y_val, predicted):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_val_bin = mlb.fit_transform(y_val)\n",
    "    predicted_bin = mlb.transform(predicted)\n",
    "\n",
    "    accuracy = accuracy_score(y_val_bin, predicted_bin)\n",
    "    f1_score_macro = f1_score(y_val_bin, predicted_bin, average='macro')\n",
    "    f1_score_micro = f1_score(y_val_bin, predicted_bin, average='micro')\n",
    "    f1_score_weighted = f1_score(y_val_bin, predicted_bin, average='weighted')\n",
    "    precision_macro = average_precision_score(y_val_bin, predicted_bin, average='macro')\n",
    "    precision_micro = average_precision_score(y_val_bin, predicted_bin, average='micro')\n",
    "    precision_weighted = average_precision_score(y_val_bin, predicted_bin, average='weighted')\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1-Score (macro, micro, weighted):\", f1_score_macro, f1_score_micro, f1_score_weighted)\n",
    "    print(\"Precision (macro, micro, weighted):\", precision_macro, precision_micro, precision_weighted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tfidf_l2')\n",
    "print_evaluation_scores(y_val, y_val_predicted_labels_tfidf_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tfidf_l2')\n",
    "print_evaluation_scores(y_val, y_val_predicted_labels_tfidf_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_val_predicted_scores_tfidf_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y_train_bin = mlb.fit_transform(y_train)\n",
    "# Convert the validation labels to binary array representation\n",
    "y_val_bin = mlb.transform(y_val)\n",
    "\n",
    "# Predict and obtain scores\n",
    "y_val_predicted_labels_tfidf_l2 = classifier_tfidf_l2.predict(X_val_tfidf)\n",
    "y_val_predicted_scores_tfidf_l2 = classifier_tfidf_l2.decision_function(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Attention, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df['TagString'] = df['TagString'].apply(lambda x: str(x).split(' '))  # Convert to strings\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_df['Body'].values)\n",
    "\n",
    "# Define the maximum sequence length\n",
    "max_sequence_length = 100\n",
    "\n",
    "# Convert the text data to sequences and pad them\n",
    "train_sequences = tokenizer.texts_to_sequences(train_df['Body'].values)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_sequence_length)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_df['Body'].values)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Create a MultiLabelBinarizer object to convert tags to binary representation\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform(train_df['TagString'])\n",
    "test_labels = mlb.transform(test_df['TagString'])\n",
    "\n",
    "# Define the data generator\n",
    "def data_generator(text_data, labels, tokenizer, max_length, batch_size):\n",
    "    num_samples = len(text_data)\n",
    "    indices = np.arange(num_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    while True:\n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            batch_indices = indices[start:end]\n",
    "            \n",
    "            batch_texts = text_data[batch_indices]\n",
    "            batch_labels = labels[batch_indices]\n",
    "            \n",
    "            batch_sequences = tokenizer.texts_to_sequences(batch_texts)\n",
    "            batch_padded = pad_sequences(batch_sequences, maxlen=max_length)\n",
    "            \n",
    "            yield batch_padded, batch_labels\n",
    "\n",
    "# Define the model architecture\n",
    "input_dim = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 100\n",
    "lstm_units = 128\n",
    "dense_units = 64\n",
    "output_units = len(mlb.classes_)\n",
    "\n",
    "input_layer = Input(shape=(max_sequence_length,))\n",
    "embedding_layer = Embedding(input_dim=input_dim, output_dim=embedding_dim)(input_layer)\n",
    "lstm_layer = LSTM(units=lstm_units, return_sequences=True)(embedding_layer)\n",
    "attention_layer = Attention()([lstm_layer, lstm_layer])\n",
    "flatten_layer = Flatten()(attention_layer)\n",
    "dense_layer = Dense(units=dense_units, activation='relu')(flatten_layer)\n",
    "output_layer = Dense(units=output_units, activation='sigmoid')(dense_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=[Accuracy()])\n",
    "\n",
    "# Define batch size and number of epochs\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "# Create data generators\n",
    "train_generator = data_generator(train_df['Body'].values, train_labels, tokenizer, max_sequence_length, batch_size)\n",
    "test_generator = data_generator(test_df['Body'].values, test_labels, tokenizer, max_sequence_length, batch_size)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, steps_per_epoch=len(train_df) // batch_size, epochs=epochs)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(test_generator, steps=len(test_df) // batch_size)\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Test script\n",
    "num_samples_to_check = 10\n",
    "test_samples = test_df.sample(num_samples_to_check)\n",
    "\n",
    "for i, sample in test_samples.iterrows():\n",
    "    question = sample['Body']\n",
    "    true_tags = sample['TagString']\n",
    "    \n",
    "    sequence = tokenizer.texts_to_sequences([question])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length)\n",
    "    \n",
    "    predicted_probs = model.predict(padded_sequence)[0]\n",
    "    predicted_tags = mlb.classes_[predicted_probs >= 0.5]\n",
    "    \n",
    "    print('---')\n",
    "    print('Question:', question)\n",
    "    print('True Tags:', true_tags)\n",
    "    print('Predicted Tags:', predicted_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'trained_model.h5'\n",
    "\n",
    "# Save the model\n",
    "model.save(model_path)\n",
    "\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
